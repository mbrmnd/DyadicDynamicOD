{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "## In this file, we create a dyadic dataset from the word embeddings of 10K filing reports. To do so, in the beginning, there are some file reading and filtering, which might be time-consuming to run. So, if you have the file titled \"words_vector_filtered,\" you can skip to the section mentioning the beginning of the code.\n",
    "\n",
    "Note: The difference between this file and 10K_embeddings is that we combine the Compustat file and filter firms with low total assets and the number of analysts' coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import jason\n",
    "import jsonlines\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrds_vector_filter= pd.read_csv('.../wrds_vector_filter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103447"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrds_vector_filter.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrds_index= pd.read_csv('.../wrds_index.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excluding firm having not been covered by any analyst in a given year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrds_vector_filter.rename(columns={'cusip_8': 'CUSIP'}, inplace=True)\n",
    "wrds_vector_filter ['CUSIP'] = wrds_vector_filter['CUSIP'].str.strip()\n",
    "wrds_vector_filter ['CUSIP'] = wrds_vector_filter['CUSIP'].str.upper()\n",
    "wrds_vector_filter ['CUSIP'] = wrds_vector_filter['CUSIP'].astype(str)\n",
    "wrds_vector_filter ['CUSIP'] = wrds_vector_filter ['CUSIP'].astype(str).str.zfill(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the analysts estimate to eliminate firms with no analysts coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8d/hsy71hlj20q70n8qz1r3s4s00000gn/T/ipykernel_24009/1371284930.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  eps_estimate= pd.read_csv('/Users/milad/Desktop/Dynamic Dyadic OD/10K embeddings Dataset/EPS_estimate_1FPI.csv') # analyst-by-analyst forecast file\n"
     ]
    }
   ],
   "source": [
    "eps_estimate= pd.read_csv('.../EPS_estimate_1FPI.csv') # analyst-by-analyst forecast file\n",
    "\n",
    "eps_estimate ['CUSIP'] = eps_estimate['CUSIP'].str.strip()\n",
    "eps_estimate ['CUSIP'] = eps_estimate['CUSIP'].str.upper()\n",
    "eps_estimate ['CUSIP'] = eps_estimate['CUSIP'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICKER</th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>OFTIC</th>\n",
       "      <th>CNAME</th>\n",
       "      <th>ACTDATS</th>\n",
       "      <th>ESTIMATOR</th>\n",
       "      <th>ANALYS</th>\n",
       "      <th>CURRFL</th>\n",
       "      <th>PDF</th>\n",
       "      <th>FPI</th>\n",
       "      <th>MEASURE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>CURR</th>\n",
       "      <th>USFIRM</th>\n",
       "      <th>FPEDATS</th>\n",
       "      <th>ACTTIMS</th>\n",
       "      <th>REVDATS</th>\n",
       "      <th>REVTIMS</th>\n",
       "      <th>ANNDATS</th>\n",
       "      <th>ANNTIMS</th>\n",
       "      <th>ACTUAL</th>\n",
       "      <th>ACTDATS_ACT</th>\n",
       "      <th>ACTTIMS_ACT</th>\n",
       "      <th>ANNDATS_ACT</th>\n",
       "      <th>ANNTIMS_ACT</th>\n",
       "      <th>CURR_ACT</th>\n",
       "      <th>report_curr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000</td>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>2014-03-11</td>\n",
       "      <td>149</td>\n",
       "      <td>119962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>EPS</td>\n",
       "      <td>0.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>15:17:12</td>\n",
       "      <td>2014-03-11</td>\n",
       "      <td>15:17:12</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>17:05:00</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>16:54:47</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>16:30:00</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000</td>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>2014-03-11</td>\n",
       "      <td>228</td>\n",
       "      <td>80474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>EPS</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>15:49:22</td>\n",
       "      <td>2014-03-11</td>\n",
       "      <td>15:49:22</td>\n",
       "      <td>2014-03-10</td>\n",
       "      <td>6:48:00</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>16:54:47</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>16:30:00</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TICKER     CUSIP OFTIC           CNAME     ACTDATS  ESTIMATOR  ANALYS  \\\n",
       "0   0000  87482X10  TLMR  TALMER BANCORP  2014-03-11        149  119962   \n",
       "1   0000  87482X10  TLMR  TALMER BANCORP  2014-03-11        228   80474   \n",
       "\n",
       "  CURRFL PDF  FPI MEASURE  VALUE  CURR  USFIRM     FPEDATS   ACTTIMS  \\\n",
       "0    NaN   D    1     EPS   0.73   NaN       1  2014-12-31  15:17:12   \n",
       "1    NaN   D    1     EPS   0.83   NaN       1  2014-12-31  15:49:22   \n",
       "\n",
       "      REVDATS   REVTIMS     ANNDATS   ANNTIMS  ACTUAL ACTDATS_ACT ACTTIMS_ACT  \\\n",
       "0  2014-03-11  15:17:12  2014-03-09  17:05:00    1.21  2015-01-30    16:54:47   \n",
       "1  2014-03-11  15:49:22  2014-03-10   6:48:00    1.21  2015-01-30    16:54:47   \n",
       "\n",
       "  ANNDATS_ACT ANNTIMS_ACT CURR_ACT report_curr  \n",
       "0  2015-01-30    16:30:00      USD         USD  \n",
       "1  2015-01-30    16:30:00      USD         USD  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_estimate.iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysts_year_firm= eps_estimate.groupby(['CUSIP', 'FPEDATS'])['ANALYS'].unique().reset_index(name='analysts_year_firm')\n",
    "\n",
    "analysts_year_firm['datadate']= analysts_year_firm['FPEDATS']\n",
    "\n",
    "analysts_year_firm ['analysts_focal_number'] = analysts_year_firm ['analysts_year_firm'].apply(lambda x: len(x) if isinstance(x, (list, np.ndarray)) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>FPEDATS</th>\n",
       "      <th>analysts_year_firm</th>\n",
       "      <th>datadate</th>\n",
       "      <th>analysts_focal_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000000</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>[125563, 122859, 113263, 113260, 113264, 113271]</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000000</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>[155036]</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000000</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>[142052, 137068]</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CUSIP     FPEDATS                                analysts_year_firm  \\\n",
       "0  00000000  2010-12-31  [125563, 122859, 113263, 113260, 113264, 113271]   \n",
       "1  00000000  2016-06-30                                          [155036]   \n",
       "2  00000000  2016-12-31                                  [142052, 137068]   \n",
       "\n",
       "     datadate  analysts_focal_number  \n",
       "0  2010-12-31                      6  \n",
       "1  2016-06-30                      1  \n",
       "2  2016-12-31                      2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysts_year_firm.iloc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminating firms with no analyst coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysts_year_firm= analysts_year_firm [analysts_year_firm['analysts_focal_number'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrds_vector_filter = pd.merge(wrds_vector_filter, analysts_year_firm, on=['CUSIP', 'datadate'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excluding financial and utility sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8d/hsy71hlj20q70n8qz1r3s4s00000gn/T/ipykernel_94559/2131796831.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  wrds_index ['datadate'] = pd.to_datetime(wrds_index['datadate'])\n"
     ]
    }
   ],
   "source": [
    "wrds_index ['datadate'] = pd.to_datetime(wrds_index['datadate'])\n",
    "wrds_vector_filter['datadate'] = pd.to_datetime(wrds_vector_filter['datadate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrds_vector_filter = pd.merge(wrds_vector_filter, wrds_index [['GVKEY','datadate', 'naicsh2', 'naicsh4']] , on=['GVKEY','datadate'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrds_vector_filter = wrds_vector_filter [ (wrds_vector_filter['naicsh2'] != 22) &\n",
    "                                         (wrds_vector_filter['naicsh2'] != 52) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52234"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrds_vector_filter.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This wrds_vector_filter only contains firms with a condition on analysts coverage (more than 1) and the exclusion of naicsh2 equal to 22 and 52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding competitors in each year/ Firm-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GVKEY</th>\n",
       "      <th>datadate</th>\n",
       "      <th>cik</th>\n",
       "      <th>conm</th>\n",
       "      <th>rdate</th>\n",
       "      <th>fdate</th>\n",
       "      <th>file_id</th>\n",
       "      <th>regsic</th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>...</th>\n",
       "      <th>yearr</th>\n",
       "      <th>monthr</th>\n",
       "      <th>yeard</th>\n",
       "      <th>monthd</th>\n",
       "      <th>year_modified</th>\n",
       "      <th>FPEDATS</th>\n",
       "      <th>analysts_year_firm</th>\n",
       "      <th>analysts_focal_number</th>\n",
       "      <th>naicsh2</th>\n",
       "      <th>naicsh4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 789 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [GVKEY, datadate, cik, conm, rdate, fdate, file_id, regsic, CUSIP, embedding_0, embedding_1, embedding_2, embedding_3, embedding_4, embedding_5, embedding_6, embedding_7, embedding_8, embedding_9, embedding_10, embedding_11, embedding_12, embedding_13, embedding_14, embedding_15, embedding_16, embedding_17, embedding_18, embedding_19, embedding_20, embedding_21, embedding_22, embedding_23, embedding_24, embedding_25, embedding_26, embedding_27, embedding_28, embedding_29, embedding_30, embedding_31, embedding_32, embedding_33, embedding_34, embedding_35, embedding_36, embedding_37, embedding_38, embedding_39, embedding_40, embedding_41, embedding_42, embedding_43, embedding_44, embedding_45, embedding_46, embedding_47, embedding_48, embedding_49, embedding_50, embedding_51, embedding_52, embedding_53, embedding_54, embedding_55, embedding_56, embedding_57, embedding_58, embedding_59, embedding_60, embedding_61, embedding_62, embedding_63, embedding_64, embedding_65, embedding_66, embedding_67, embedding_68, embedding_69, embedding_70, embedding_71, embedding_72, embedding_73, embedding_74, embedding_75, embedding_76, embedding_77, embedding_78, embedding_79, embedding_80, embedding_81, embedding_82, embedding_83, embedding_84, embedding_85, embedding_86, embedding_87, embedding_88, embedding_89, embedding_90, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 789 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_df = wrds_vector_filter [wrds_vector_filter.duplicated(subset=['GVKEY', 'year_modified'], keep=False)]\n",
    "\n",
    "duplicated_df\n",
    "\n",
    "# They published a 10-K report in less than a year (around 6 month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993\n",
      "2022\n"
     ]
    }
   ],
   "source": [
    "print(wrds_vector_filter['year_modified'].min())\n",
    "print(wrds_vector_filter['year_modified'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Competitors or Dyads\n",
    "We can skip this section as we have saved the results_nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results_25 = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the 10 most similar:\n",
    "\n",
    "\n",
    "### I temporally changed the code to 10. As we have the data for 10, we can sort for other number of rivals.\n",
    "### I created two datasets: one restricts the firms based on NAICS H2 and similaraity at the same time, while the other focuses only on the similarity indices among firms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique years and iterate over each year\n",
    "# The for loop starts from the tM1\n",
    "\n",
    "for year in sorted(wrds_vector_filter['year_modified'].unique())[0:]: \n",
    "    \n",
    "    t0_data = wrds_vector_filter[wrds_vector_filter['year_modified'] == year]\n",
    "    \n",
    "    t1_data = wrds_vector_filter[wrds_vector_filter['year_modified'] == year+1]\n",
    "    \n",
    "    t2_data = wrds_vector_filter[wrds_vector_filter['year_modified'] == year+2]\n",
    "\n",
    "    common_gvkeys = set(t1_data['GVKEY']).intersection(set(t2_data['GVKEY']))\n",
    "    \n",
    "    # common_gvkeys = set(previous_year_data['GVKEY']).intersection(set(next_year_data['GVKEY']), set(before_previous_year_data['GVKEY']))\n",
    "    t0_data= t0_data[t0_data['GVKEY'].isin(common_gvkeys)]\n",
    "    \n",
    "    # Get the unique firms in current year\n",
    "    for firm in t0_data['GVKEY'].unique():\n",
    "\n",
    "        t0_firm = t0_data [t0_data['GVKEY'] == firm]\n",
    "        \n",
    "        firm_naics_code = t0_firm['naicsh2'].iloc[0]\n",
    "                \n",
    "        t0_other_firms = t0_data [ (t0_data['GVKEY'] != firm)] \n",
    "        \n",
    "        #Additional condition for finding competitors\n",
    "        # t0_other_firms = t0_data [ (t0_data['GVKEY'] != firm) & (t0_data['naicsh2'] == firm_naics_code)] \n",
    "\n",
    "        \n",
    "        if t0_other_firms.empty:\n",
    "            continue  \n",
    "        \n",
    "        # Compute cosine similarity between current firm and others\n",
    "        embedding_columns = [column for column in wrds_vector_filter.columns if 'embedding' in column]\n",
    "        \n",
    "        similarity_scores = cosine_similarity(t0_firm [embedding_columns], t0_other_firms [embedding_columns])\n",
    "        \n",
    "        t0_other_firms ['similarity'] = similarity_scores[0] # all the similarity scores (check the above example)\n",
    "\n",
    "        # Get the top 5 firms with highest similarity scores\n",
    "        top_10_firms = t0_other_firms.sort_values(by='similarity', ascending=False).head(10)['GVKEY'].values\n",
    "\n",
    "        # Store in result\n",
    "        results[(firm, year)] = top_10_firms.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the 25 most similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique years and iterate over each year\n",
    "# The for loop starts from the tM1\n",
    "\n",
    "for year in sorted(wrds_vector_filter['year_modified'].unique())[0:]: \n",
    "    \n",
    "    t0_data = wrds_vector_filter[wrds_vector_filter['year_modified'] == year]\n",
    "    \n",
    "    t1_data = wrds_vector_filter[wrds_vector_filter['year_modified'] == year+1]\n",
    "    \n",
    "    t2_data = wrds_vector_filter[wrds_vector_filter['year_modified'] == year+2]\n",
    "\n",
    "    common_gvkeys = set(t1_data['GVKEY']).intersection(set(t2_data['GVKEY']))\n",
    "    \n",
    "    # common_gvkeys = set(previous_year_data['GVKEY']).intersection(set(next_year_data['GVKEY']), set(before_previous_year_data['GVKEY']))\n",
    "    \n",
    "    t0_data= t0_data[t0_data['GVKEY'].isin(common_gvkeys)]\n",
    "\n",
    "    # Get the unique firms in current year\n",
    "    for firm in t0_data['GVKEY'].unique():\n",
    "\n",
    "        t0_firm = t0_data [t0_data['GVKEY'] == firm]\n",
    "        \n",
    "        # t0_other_firms = t0_data [t0_data['GVKEY'] != firm] \n",
    "        firm_naics_code = t0_firm['naicsh2'].iloc[0]\n",
    "                \n",
    "        t0_other_firms = t0_data [ (t0_data['GVKEY'] != firm)] \n",
    "        \n",
    "        # The additional condition for finding competitors\n",
    "        # t0_other_firms = t0_data [ (t0_data['GVKEY'] != firm) & (t0_data['naicsh2'] == firm_naics_code)] \n",
    "\n",
    "        \n",
    "        if t0_other_firms.empty:\n",
    "            continue  \n",
    "        \n",
    "        # Get those firms that had observation in the t0 and t1 years\n",
    "                \n",
    "        # Compute cosine similarity between current firm and others\n",
    "        embedding_columns = [column for column in wrds_vector_filter.columns if 'embedding' in column]\n",
    "\n",
    "        similarity_scores = cosine_similarity(t0_firm [embedding_columns], t0_other_firms [embedding_columns])\n",
    "        \n",
    "        t0_other_firms ['similarity'] = similarity_scores[0] # all the similarity scores (check the above example)\n",
    "\n",
    "        # Get the top 25 firms with highest similarity scores\n",
    "        top_25_firms = t0_other_firms.sort_values(by='similarity', ascending=False).head(25)['GVKEY'].values\n",
    "\n",
    "        # Store in result\n",
    "        results_25 [(firm, year)] = top_25_firms.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nest = {}\n",
    "\n",
    "# Loop over the keys and values in the original dictionary\n",
    "for (gv, year), value in results.items():\n",
    "\n",
    "    if year not in results_nest:\n",
    "        results_nest[year] = {}\n",
    "    \n",
    "    # Add the firm and value to the appropriate year in the new dictionary\n",
    "    results_nest[year][gv] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nest_25 = {}\n",
    "\n",
    "# Loop over the keys and values in the original dictionary\n",
    "for (gv, year), value in results_25.items():\n",
    "\n",
    "    if year not in results_nest_25:\n",
    "        results_nest_25[year] = {}\n",
    "    \n",
    "    # Add the firm and value to the appropriate year in the new dictionary\n",
    "    results_nest_25[year][gv] = value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the main data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For building the 10\n",
    "\n",
    "main_dict={'year_modified':[], 'datadateF':[], 'fdate':[], 'GVKEY focal':[],'GVKEY peer':[], 'Cos_f1_p0':[],\n",
    "           'Cos_f1_p1':[], 'Cos_f0_p0':[], 'Cos_f0_p1':[], 'Cos_f2_p1':[], 'Cos_f2_p2':[], 'Cos_f1_p2':[], \n",
    "           'Cos_f0_p2':[], 'Cos_f4_p2':[], 'Cos_f3_p1':[]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For building the 25\n",
    "main_dict_25 = {'year_modified':[], 'datadateF':[], 'fdate':[], 'GVKEY focal':[],'GVKEY peer':[], 'Cos_f1_p1':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intended Variables: \n",
    "Change_similarity_f0p0 (willingness for imitation): The comparison of change between the focal and peer at t0\n",
    "\n",
    "Change_similarity_f1p0: The comparison of change between the change of the focal at t1 and peer at t0\n",
    "\n",
    "Peer_change_toward_f0p0 (The extent of imitation): The magnitude of peer firms' changes (at t0) is multiplied by the change_similarity_f0p0\n",
    "In other words, to what extent the peer firm's change is similar to the focal firm's at t0\n",
    "\n",
    "Focal_change_toward_f1p0: The magnitude of focal firms' changes (at t1) is multiplied by the change_similarity_f1p0\n",
    "In other words, to what extent the focal firm's change t1 change is similar to the peer firm's t0 change\n",
    "\n",
    "Cos_f0_pM1: The cosine between the position of the peer firm at (t-1) and the focal at t0\n",
    "\n",
    "Cos_f0_p0: The cosine between the position of the peer firm at (t0) and the focal at t0\n",
    "\n",
    "Cos_f1_p0: The cosine between the position of the peer firm at (t0) and the focal at t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanations of files used: \n",
    "\n",
    "results[1013, 2007] find the competitors of a firm in a given year with GVKEY\n",
    "\n",
    "results_nest [2007][1013] a nested version of the above format.\n",
    "\n",
    "wrds_vector_filter for finding embeddings of focal and peer firm in different years. \n",
    "\n",
    "Starts from the t0 (between 't-2' and 't1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrds_vector_filter ['datadate']= pd.to_datetime(wrds_vector_filter['datadate'])\n",
    "wrds_vector_filter['fdate']= pd.to_datetime(wrds_vector_filter['fdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_cols = ['embedding_' + str(i) for i in range(768)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (min(results_nest.keys()))\n",
    "print (max (results_nest.keys()))\n",
    "\n",
    "# print (min(results_nest_25.keys()))\n",
    "# print (max (results_nest_25.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the following for building the 25 rival firms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0_min= 1993\n",
    "# t0_max= 2020 \n",
    "\n",
    "embed_cols = ['embedding_' + str(i) for i in range(768)]\n",
    "\n",
    "for year, focals in results_nest_25.items():    \n",
    "    \n",
    "    for focal, peers in focals.items():        \n",
    "        \n",
    "        for peer in peers:\n",
    "\n",
    "            #year column\n",
    "            year_mod = wrds_vector_filter['year_modified'][(wrds_vector_filter['GVKEY'] == focal) & \n",
    "                                                          (wrds_vector_filter['year_modified']== year+1)].values[0]\n",
    "            main_dict_25 ['year_modified'].append(year_mod)\n",
    "\n",
    "            main_dict_25 ['GVKEY focal'].append(focal)\n",
    "\n",
    "            main_dict_25 ['GVKEY peer'].append(peer)\n",
    "            \n",
    "            datadate = wrds_vector_filter['datadate'][(wrds_vector_filter['GVKEY']== focal) & (wrds_vector_filter['year_modified']== year+1)].dt.strftime('%Y-%m-%d').values[0]\n",
    "            main_dict_25 ['datadateF'].append(datadate)\n",
    "            \n",
    "            fdate= wrds_vector_filter['fdate'][(wrds_vector_filter['GVKEY']== focal) & (wrds_vector_filter['year_modified']== year+1)].dt.strftime('%Y-%m-%d').values[0]\n",
    "            main_dict_25 ['fdate'].append(fdate)\n",
    "            \n",
    "            \n",
    "            # For building the 5\n",
    "            companies = [focal, peer]\n",
    "            \n",
    "            # filter the data for companies (focal and peer) at t2\n",
    "            filtered_data_t1 = wrds_vector_filter[(wrds_vector_filter['year_modified'] == year+1) & (wrds_vector_filter['GVKEY'].isin(companies))]\n",
    "            \n",
    "            # find the vector of embeddings\n",
    "            embeddings_focal_t1 = filtered_data_t1 [filtered_data_t1 ['GVKEY'] == companies[0]][embed_cols].values\n",
    "                        \n",
    "            embeddings_peer_t1 = filtered_data_t1 [filtered_data_t1['GVKEY'] == companies[1]][embed_cols].values\n",
    "            \n",
    "            #find the similaty at time t2\n",
    "            similarity_f1p1 = cosine_similarity(embeddings_focal_t1, embeddings_peer_t1)[0][0]\n",
    "            main_dict_25['Cos_f1_p1'].append(similarity_f1p1)\n",
    "            \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataframe_25 = pd.DataFrame(main_dict_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the following for building the 10 rival firms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t0_min= 1993\n",
    "# t0_max= 2020 \n",
    "\n",
    "\n",
    "embed_cols = ['embedding_' + str(i) for i in range(768)]\n",
    "\n",
    "for year, focals in results_nest.items():    \n",
    "    \n",
    "    for focal, peers in focals.items():        \n",
    "        \n",
    "        for peer in peers:\n",
    "\n",
    "            #year column\n",
    "            year_mod_t1 = wrds_vector_filter['year_modified'][(wrds_vector_filter['GVKEY'] == focal) & \n",
    "                                                          (wrds_vector_filter['year_modified']== year+1)].values[0]\n",
    "            main_dict['year_modified'].append(year_mod_t1)\n",
    "            main_dict['GVKEY focal'].append(focal)\n",
    "            main_dict['GVKEY peer'].append(peer)\n",
    "            datadate = wrds_vector_filter['datadate'][(wrds_vector_filter['GVKEY']== focal) & (wrds_vector_filter['year_modified']== year+1)].dt.strftime('%Y-%m-%d').values[0]\n",
    "            main_dict['datadateF'].append(datadate)\n",
    "            fdate= wrds_vector_filter['fdate'][(wrds_vector_filter['GVKEY']== focal) & (wrds_vector_filter['year_modified']== year+1 )].dt.strftime('%Y-%m-%d').values[0]\n",
    "            main_dict['fdate'].append(fdate)\n",
    "            \n",
    "            \n",
    "            companies = [focal, peer]\n",
    "            filtered_data_t1 = wrds_vector_filter[(wrds_vector_filter['year_modified'] == year+1) & (wrds_vector_filter['GVKEY'].isin(companies))]\n",
    "            \n",
    "            # find the vector of embeddings\n",
    "            embeddings_focal_t1 = filtered_data_t1[filtered_data_t1['GVKEY'] == companies[0]][embed_cols].values\n",
    "            embeddings_peer_t1 = filtered_data_t1[filtered_data_t1['GVKEY'] == companies[1]][embed_cols].values\n",
    "            \n",
    "            embeddings_focal_t0 = wrds_vector_filter[(wrds_vector_filter['year_modified'] == year) & (wrds_vector_filter['GVKEY'] == focal)][embed_cols].values\n",
    "            embeddings_peer_t0 = wrds_vector_filter[(wrds_vector_filter['year_modified'] == year) & (wrds_vector_filter['GVKEY'] == peer)][embed_cols].values\n",
    "\n",
    "            similarity_f0p1 = cosine_similarity(embeddings_focal_t0, embeddings_peer_t1)[0][0]\n",
    "            similarity_f1p1 = cosine_similarity(embeddings_focal_t1, embeddings_peer_t1)[0][0]\n",
    "            similarity_f0p0 = cosine_similarity(embeddings_focal_t0, embeddings_peer_t0)[0][0]\n",
    "            similarity_f1p0 = cosine_similarity(embeddings_focal_t1, embeddings_peer_t0)[0][0]\n",
    "\n",
    "            main_dict['Cos_f0_p1'].append(similarity_f0p1)\n",
    "            main_dict['Cos_f1_p1'].append(similarity_f1p1)\n",
    "            main_dict['Cos_f0_p0'].append(similarity_f0p0)\n",
    "            main_dict['Cos_f1_p0'].append(similarity_f1p0)\n",
    "\n",
    "            #focal and peer firm embeddings t1\n",
    "            embeddings_focal_t2 = wrds_vector_filter[(wrds_vector_filter['year_modified'] == year+2) & (wrds_vector_filter['GVKEY'] == focal)][embed_cols].values\n",
    "            embeddings_peer_t2 = wrds_vector_filter[(wrds_vector_filter['year_modified'] == year+2) & (wrds_vector_filter['GVKEY'] == peer)][embed_cols].values\n",
    "\n",
    "            similarity_f2p1 = cosine_similarity (embeddings_focal_t2, embeddings_peer_t1 )[0][0]\n",
    "            similarity_f2p2 = cosine_similarity (embeddings_focal_t2, embeddings_peer_t2 )[0][0]\n",
    "            similarity_f1p2 = cosine_similarity (embeddings_focal_t1, embeddings_peer_t2 )[0][0]\n",
    "\n",
    "            main_dict['Cos_f2_p1'].append(similarity_f2p1)\n",
    "            main_dict['Cos_f2_p2'].append(similarity_f2p2)\n",
    "            main_dict['Cos_f1_p2'].append(similarity_f1p2)\n",
    "                     \n",
    "            \n",
    "            # Robustness Check:\n",
    "            \n",
    "            similarity_f0_p2= cosine_similarity(embeddings_focal_t0, embeddings_peer_t2)[0][0]\n",
    "            main_dict['Cos_f0_p2'].append(similarity_f0_p2)\n",
    "            \n",
    "            # Emeddings for t3 and t4\n",
    "                            \n",
    "            embeddings_focal_t4 = wrds_vector_filter[(wrds_vector_filter['year_modified'] == year+4) & (wrds_vector_filter['GVKEY'] == focal)][embed_cols].values\n",
    "            \n",
    "            if embeddings_focal_t4.size > 0:\n",
    "                similarity_f4_p2 = cosine_similarity(embeddings_focal_t4, embeddings_peer_t2)[0][0]\n",
    "            else:\n",
    "                similarity_f4_p2 = np.nan  # Assign NaN if embeddings are not found\n",
    "\n",
    "            main_dict['Cos_f4_p2'].append(similarity_f4_p2)\n",
    "\n",
    "\n",
    "            embeddings_focal_t3 = wrds_vector_filter[(wrds_vector_filter['year_modified'] == year+3) & (wrds_vector_filter['GVKEY'] == focal)][embed_cols].values\n",
    "            \n",
    "            if embeddings_focal_t3.size > 0:\n",
    "                similarity_f3_p1 = cosine_similarity(embeddings_focal_t3, embeddings_peer_t1)[0][0]\n",
    "            else:\n",
    "                similarity_f3_p1 = np.nan  # Assign NaN if embeddings are not found\n",
    "\n",
    "            main_dict['Cos_f3_p1'].append(similarity_f3_p1)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataframe = pd.DataFrame(main_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348520\n",
      "871300\n"
     ]
    }
   ],
   "source": [
    "print (main_dataframe.shape[0])\n",
    "print (main_dataframe_25.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It excludes the finance and utility companies\n",
    "# Only includes firms having at least one analyst covering them.  \n",
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# Format the date as YYYYMMDD\n",
    "formatted_date = today.strftime('%Y%m%d')\n",
    "\n",
    "# Create a filename using the date\n",
    "filename = f\"main_dataframe_10R_{formatted_date}.csv\"\n",
    "\n",
    "main_dataframe.to_csv(filename, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It excludes the finance and utility companies\n",
    "# Only includes firms having at least one analyst covering them. \n",
    "\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# Format the date as YYYYMMDD\n",
    "formatted_date = today.strftime('%Y%m%d')\n",
    "\n",
    "# Create a filename using the date\n",
    "filename25 = f\"main_dataframe_t2_25R_{formatted_date}.csv\"\n",
    "\n",
    "main_dataframe_25.to_csv(filename25, index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "31232e78c4309ced8f2c029626445b210e498e1ea5bcf01f25854a2c65a5b90f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
